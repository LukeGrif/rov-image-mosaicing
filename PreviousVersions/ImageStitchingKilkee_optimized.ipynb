{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MMgdx5hhgxX9"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------- config ---------------------\n",
    "DEBUG = False  # turn off verbose output by default\n",
    "RATIO_TEST = 0.75\n",
    "RANSAC_THRESH = 3.0\n",
    "RESIZE_MAX = 900  # downscale for speed\n",
    "MAX_CANVAS = 8000  # clamp max canvas width/height in pixels\n",
    "# --------------------------------------------------\n",
    "\n",
    "def show_img(img, title=\"\"):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(cv.cvtColor(img.astype(np.uint8), cv.COLOR_BGR2RGB))\n",
    "    plt.title(title); plt.axis(\"off\"); plt.show()\n",
    "\n",
    "def draw_polys_debug(canvas_size, images, H_to_anchor, canvas_T):\n",
    "    vis = np.zeros((canvas_size[1], canvas_size[0], 3), np.uint8)\n",
    "    for i, (img, H) in enumerate(zip(images, H_to_anchor)):\n",
    "        h, w = img.shape[:2]\n",
    "        cs = np.float32([[0,0],[w,0],[w,h],[0,h]]).reshape(-1,1,2)\n",
    "        wc = cv.perspectiveTransform(cs, canvas_T @ H).reshape(-1,2).astype(np.int32)\n",
    "        cv.polylines(vis, [wc.reshape(-1,1,2)], True, (0,255,0), 2)\n",
    "        cx, cy = wc.mean(axis=0).astype(int)\n",
    "        cv.putText(vis, str(i), (cx, cy), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    show_img(vis, \"Warped footprints with IDs\")\n",
    "\n",
    "def imread_color(p):\n",
    "    img = cv.imread(str(p), cv.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise RuntimeError(f\"Failed to read {p}\")\n",
    "    if RESIZE_MAX is not None:\n",
    "        h, w = img.shape[:2]\n",
    "        s = RESIZE_MAX / max(h, w)\n",
    "        if s < 1.0:\n",
    "            img = cv.resize(img, (int(w*s), int(h*s)), interpolation=cv.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def to_gray(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "x3_gN49vgxTL"
   },
   "outputs": [],
   "source": [
    "def detect_and_match(imgA, imgB, idxA=None, idxB=None, visualize=False):\n",
    "    sift = cv.SIFT_create(nfeatures=2500, contrastThreshold=0.02, edgeThreshold=10)\n",
    "    grayA, grayB = to_gray(imgA), to_gray(imgB)\n",
    "    kA, dA = sift.detectAndCompute(grayA, None)\n",
    "    kB, dB = sift.detectAndCompute(grayB, None)\n",
    "\n",
    "    if dA is None or dB is None or len(kA) < 8 or len(kB) < 8:\n",
    "        return None, None, None, None\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=100))\n",
    "    raw = flann.knnMatch(dA, dB, k=2)\n",
    "    good = [m for m,n in raw if m.distance < RATIO_TEST * n.distance]\n",
    "\n",
    "    if len(good) < 8:\n",
    "        return None, None, None, None\n",
    "\n",
    "    ptsA = np.float32([kA[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    ptsB = np.float32([kB[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    H, mask = cv.findHomography(ptsA, ptsB, cv.RANSAC, RANSAC_THRESH)\n",
    "\n",
    "    if idxA is not None and idxB is not None:\n",
    "        inliers = int(mask.sum()) if mask is not None else 0\n",
    "        if 'DEBUG' in globals() and DEBUG:\n",
    "            print(f\"[match] {idxA} -> {idxB} : {len(good)} matches, {inliers} inliers\")\n",
    "\n",
    "    if visualize or ('DEBUG' in globals() and DEBUG):\n",
    "        matched_vis = cv.drawMatches(imgA, kA, imgB, kB, good[:50], None,\n",
    "                                     flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        show_img(matched_vis, f\"Matches {idxA}->{idxB}\")\n",
    "\n",
    "    return H, mask, ptsA, ptsB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xhg1sOTvgxO4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _normalize_H(H):\n",
    "    if H is None:\n",
    "        return None\n",
    "    if abs(H[2,2]) < 1e-12:\n",
    "        return H\n",
    "    return H / H[2,2]\n",
    "\n",
    "def accumulate_homographies(images):\n",
    "    \"\"\"\n",
    "    Build transforms that map each image into the center (anchor) frame.\n",
    "    Robust composition with None-guarding so we never matmul with None.\n",
    "    \"\"\"\n",
    "    N = len(images)\n",
    "    if N == 0:\n",
    "        return [], 0\n",
    "    center = N // 2\n",
    "\n",
    "    H_to_anchor = [None] * N\n",
    "    H_to_anchor[center] = np.eye(3, dtype=np.float64)\n",
    "\n",
    "    # ---- forward: center -> right ----\n",
    "    # For pair (i, i+1): estimate H(i+1 <- i). To map (i+1) to anchor:\n",
    "    # H_to_anchor[i+1] = H_to_anchor[i] @ inv(H(i+1 <- i))\n",
    "    for i in range(center, N - 1):\n",
    "        H, _, _, _ = detect_and_match(images[i + 1], images[i], i+1, i, visualize=False)  # H: (i+1) <- i\n",
    "        H = _normalize_H(H)\n",
    "        if H is None:\n",
    "            # propagate last known pose\n",
    "            H_to_anchor[i + 1] = H_to_anchor[i] if H_to_anchor[i] is not None else np.eye(3, dtype=np.float64)\n",
    "            if 'DEBUG' in globals() and DEBUG:\n",
    "                print(f\"[warn] No reliable H between {i} and {i+1} (right). Pose copied.\")\n",
    "        else:\n",
    "            base = H_to_anchor[i] if H_to_anchor[i] is not None else np.eye(3, dtype=np.float64)\n",
    "            try:\n",
    "                Hinv = np.linalg.inv(H)\n",
    "            except np.linalg.LinAlgError:\n",
    "                Hinv = np.eye(3, dtype=np.float64)\n",
    "                if 'DEBUG' in globals() and DEBUG:\n",
    "                    print(f\"[warn] H between {i} and {i+1} singular; using identity.\")\n",
    "            H_to_anchor[i + 1] = base @ Hinv\n",
    "\n",
    "    # ---- backward: center -> left ----\n",
    "    # For pair (i-1, i): estimate H(i-1 -> i). To map (i-1) to anchor:\n",
    "    # H_to_anchor[i-1] = H_to_anchor[i] @ H(i-1 -> i)\n",
    "    for i in range(center, 0, -1):\n",
    "        H, _, _, _ = detect_and_match(images[i - 1], images[i], i-1, i, visualize=False)  # H: (i-1)->i\n",
    "        H = _normalize_H(H)\n",
    "        if H is None:\n",
    "            H_to_anchor[i - 1] = H_to_anchor[i] if H_to_anchor[i] is not None else np.eye(3, dtype=np.float64)\n",
    "            if 'DEBUG' in globals() and DEBUG:\n",
    "                print(f\"[warn] No reliable H between {i-1} and {i} (left). Pose copied.\")\n",
    "        else:\n",
    "            base = H_to_anchor[i] if H_to_anchor[i] is not None else np.eye(3, dtype=np.float64)\n",
    "            H_to_anchor[i - 1] = base @ H\n",
    "\n",
    "    return H_to_anchor, center\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Uw5xb2aggxKY"
   },
   "outputs": [],
   "source": [
    "PADDING = 80  # safety margin in pixels\n",
    "\n",
    "def compute_canvas_bounds(images, H_to_anchor):\n",
    "    corners = []\n",
    "    polys   = []\n",
    "    for img, H in zip(images, H_to_anchor):\n",
    "        h, w = img.shape[:2]\n",
    "        cs = np.float32([[0,0],[w,0],[w,h],[0,h]]).reshape(-1,1,2)\n",
    "        wc = cv.perspectiveTransform(cs, H)  # 4x1x2\n",
    "        corners.append(wc)\n",
    "        polys.append(wc.reshape(-1,2))       # 4x2 for drawing/debug\n",
    "\n",
    "    allc = np.vstack(corners)                # (4N,1,2)\n",
    "    x_min, y_min = np.floor(allc.min(axis=0).ravel()).astype(int)\n",
    "    x_max, y_max = np.ceil (allc.max(axis=0).ravel()).astype(int)\n",
    "\n",
    "    # padding\n",
    "    x_min -= PADDING\n",
    "    y_min -= PADDING\n",
    "    x_max += PADDING\n",
    "    y_max += PADDING\n",
    "\n",
    "    T = np.array([[1,0,-x_min],[0,1,-y_min],[0,0,1]], dtype=np.float64)\n",
    "    size = (int(x_max - x_min), int(y_max - y_min))\n",
    "    # --- clamp canvas to MAX_CANVAS ---\n",
    "    if \"MAX_CANVAS\" in globals() and MAX_CANVAS is not None:\n",
    "        max_dim = max(size)\n",
    "        if max_dim > MAX_CANVAS:\n",
    "            s = MAX_CANVAS / float(max_dim)\n",
    "            S = np.array([[s,0,0],[0,s,0],[0,0,1]], dtype=np.float64)\n",
    "            T = S @ T\n",
    "            size = (int(size[0]*s), int(size[1]*s))\n",
    "    return T, size, polys  # return polys for debug drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QQi0ZhxzgxBG"
   },
   "outputs": [],
   "source": [
    "def _robust_mean(img, mask):\n",
    "    # img: HxWx3 float32, mask: HxWx1 {0,1}\n",
    "    eps = 1e-6\n",
    "    m = mask.squeeze().astype(bool)\n",
    "    if not np.any(m):\n",
    "        return np.array([1.0, 1.0, 1.0], dtype=np.float32)\n",
    "    # robust mean via median of valid pixels per channel\n",
    "    vals = img[m]\n",
    "    med = np.median(vals, axis=0).astype(np.float32)\n",
    "    med[med < eps] = eps\n",
    "    return med\n",
    "\n",
    "def multiband_blend_warped(images, H_to_anchor, canvas_T, canvas_size, debug_show=False):\n",
    "    \"\"\"\n",
    "    Exposure-aware streaming blender (memory-safe).\n",
    "    - Per-image gain compensation on the overlap area\n",
    "    - Distance-normalized feather to avoid halos\n",
    "    - Same signature as your previous function\n",
    "    \"\"\"\n",
    "    if \"DEBUG\" in globals() and DEBUG:\n",
    "        print(\"[info] exposure-aware blending\")\n",
    "\n",
    "    Hs = [canvas_T @ H for H in H_to_anchor]\n",
    "\n",
    "    Hc, Wc = canvas_size[1], canvas_size[0]\n",
    "    canvas = np.zeros((Hc, Wc, 3), np.float32)\n",
    "    weight = np.zeros((Hc, Wc, 1), np.float32)\n",
    "\n",
    "    for i, (img, Hc_) in enumerate(zip(images, Hs)):\n",
    "        warped = cv.warpPerspective(img, Hc_, canvas_size).astype(np.float32)\n",
    "        mask = (warped.sum(axis=2, keepdims=True) > 0).astype(np.float32)\n",
    "\n",
    "        # Overlap with existing canvas?\n",
    "        overlap_mask = ((weight > 0) & (mask > 0)).astype(np.float32)\n",
    "\n",
    "        # ---- Exposure/gain compensation (per-channel) ----\n",
    "        # Compare median colors in overlap; if no overlap yet, skip.\n",
    "        if np.any(overlap_mask):\n",
    "            # Compute robust “means”\n",
    "            cur_med  = _robust_mean(warped, overlap_mask)\n",
    "            canv_med = _robust_mean(canvas / np.maximum(weight, 1e-6), overlap_mask)\n",
    "\n",
    "            gain = (canv_med / np.maximum(cur_med, 1e-6)).astype(np.float32)\n",
    "            # Clamp gains to avoid extremes\n",
    "            gain = np.clip(gain, 0.8, 1.25)\n",
    "\n",
    "            # Apply gain per channel\n",
    "            warped *= gain[None, None, :]\n",
    "        # else: first image into canvas → no compensation\n",
    "\n",
    "        # ---- Distance-to-edge feather, normalized against current canvas ----\n",
    "        # Distance of the *current* mask to its boundary\n",
    "        dt_new = cv.distanceTransform((mask.squeeze()>0).astype(np.uint8), cv.DIST_L2, 3).astype(np.float32)\n",
    "        if dt_new.max() > 0:\n",
    "            dt_new /= dt_new.max()\n",
    "        w_new = (0.1 + 0.9*dt_new)[..., None] * mask  # keep a floor to avoid zero-division\n",
    "\n",
    "        # If there is already weight at those pixels, normalize so the sum stays smooth\n",
    "        w_sum = w_new + weight\n",
    "        # Where there is overlap, make the share proportional to each side\n",
    "        w_new = np.where(w_sum > 1e-6, (w_new / w_sum), w_new)\n",
    "\n",
    "        # Accumulate\n",
    "        canvas = canvas * (1.0 - w_new) + warped * w_new\n",
    "        weight = np.maximum(weight, w_new)  # track coverage/soft max (prevents runaway weight)\n",
    "\n",
    "        if debug_show and ('DEBUG' in globals() and DEBUG):\n",
    "            print(f\"[blend] {i+1}/{len(images)}\")\n",
    "\n",
    "        # Free per-iter buffers\n",
    "        del warped, mask, overlap_mask, dt_new, w_new, w_sum\n",
    "        gc.collect()\n",
    "\n",
    "    out = np.clip(canvas, 0, 255).astype(np.uint8)\n",
    "    if debug_show and ('DEBUG' in globals() and DEBUG):\n",
    "        show_img(out, \"Exposure-aware mosaic\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JXwARnCYAP9v"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "MIN_RUN_LEN = 9  # require more than 8 images in a row to mosaic\n",
    "\n",
    "def stitch_folder_split(folder_glob, out_prefix=\"mosaic\"):\n",
    "    files = sorted(glob.glob(folder_glob))\n",
    "    if not files:\n",
    "        raise SystemExit(\"No images found\")\n",
    "\n",
    "    imgs = [imread_color(f) for f in files]\n",
    "    if \"DEBUG\" in globals() and DEBUG:\n",
    "        print(f\"[info] loaded {len(imgs)} images\")\n",
    "\n",
    "    # Break into subgroups whenever matches fail\n",
    "    subgroups = []\n",
    "    current = [imgs[0]]\n",
    "\n",
    "    for i in range(1, len(imgs)):\n",
    "        H, _, _, _ = detect_and_match(imgs[i], imgs[i-1], i, i-1)\n",
    "        if H is None:\n",
    "            print(f\"[split] No match between {i-1} and {i} → splitting mosaic here\")\n",
    "            subgroups.append(current)\n",
    "            current = [imgs[i]]\n",
    "        else:\n",
    "            current.append(imgs[i])\n",
    "    subgroups.append(current)\n",
    "\n",
    "    print(f\"[info] formed {len(subgroups)} mosaics\")\n",
    "\n",
    "    # Stitch each subgroup\n",
    "    subgroups = [g for g in subgroups if len(g) >= MIN_RUN_LEN]\n",
    "    if 'DEBUG' in globals() and DEBUG:\n",
    "        print(f\"[info] kept {len(subgroups)} subgroups with >= {MIN_RUN_LEN} images\")\n",
    "        # Free original list to save memory\n",
    "    del imgs\n",
    "    gc.collect()\n",
    "    for gi, group in enumerate(subgroups):\n",
    "        if len(group) < 2:\n",
    "            print(f\"[skip] group {gi} has only 1 image\")\n",
    "            continue\n",
    "\n",
    "        if \"DEBUG\" in globals() and DEBUG:\n",
    "            print(f\"[info] stitching group {gi} with {len(group)} images\")\n",
    "        H_to_anchor, _ = accumulate_homographies(group)\n",
    "        T, canvas_size = compute_canvas_bounds(group, H_to_anchor)\n",
    "        if \"DEBUG\" in globals() and DEBUG:\n",
    "            print(f\"[info] group {gi} canvas size: {canvas_size}\")\n",
    "\n",
    "        mosaic = multiband_blend_warped(group, H_to_anchor, T, canvas_size)\n",
    "        out_path = f\"{out_prefix}_{gi}.png\"\n",
    "        cv.imwrite(out_path, mosaic)\n",
    "        print(f\"[done] wrote {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7LOptmYXg7IJ",
    "outputId": "dd4b6cd9-33b7-40a3-c786-e0bc173a65f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] formed 113 subgroups\n",
      "[info] stitching subgroup 0 with 8 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke Griffin\\AppData\\Local\\Temp\\ipykernel_50848\\3039165138.py:61: RuntimeWarning: invalid value encountered in divide\n",
      "  w_new = np.where(w_sum > 1e-6, (w_new / w_sum), w_new)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] wrote mosaic_0.png\n",
      "[info] stitching subgroup 1 with 5 images\n",
      "[done] wrote mosaic_1.png\n",
      "[info] stitching subgroup 2 with 17 images\n",
      "[done] wrote mosaic_2.png\n",
      "[info] stitching subgroup 3 with 24 images\n",
      "[done] wrote mosaic_3.png\n",
      "[info] stitching subgroup 4 with 7 images\n",
      "[done] wrote mosaic_4.png\n",
      "[info] stitching subgroup 5 with 11 images\n",
      "[done] wrote mosaic_5.png\n",
      "[info] stitching subgroup 6 with 5 images\n",
      "[done] wrote mosaic_6.png\n",
      "[info] stitching subgroup 7 with 7 images\n",
      "[done] wrote mosaic_7.png\n",
      "[info] stitching subgroup 8 with 6 images\n",
      "[done] wrote mosaic_8.png\n",
      "[info] stitching subgroup 9 with 13 images\n",
      "[done] wrote mosaic_9.png\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "MIN_RUN_LEN = 4\n",
    "\n",
    "files = sorted(glob.glob(\"Killaloe/*.jpg\"))\n",
    "if not files:\n",
    "    raise SystemExit(\"No images found\")\n",
    "\n",
    "imgs = [imread_color(f) for f in files]\n",
    "if \"DEBUG\" in globals() and DEBUG:\n",
    "    print(f\"[info] loaded {len(imgs)} images\")\n",
    "\n",
    "# --- split into subgroups whenever matches fail ---\n",
    "subgroups = []\n",
    "current = [imgs[0]]\n",
    "for i in range(1, len(imgs)):\n",
    "    H, _, _, _ = detect_and_match(imgs[i], imgs[i-1], i, i-1)\n",
    "    if H is None:\n",
    "        if \"DEBUG\" in globals() and DEBUG:\n",
    "            print(f\"[split] No match between {i-1} and {i} → new subgroup\")\n",
    "        subgroups.append(current)\n",
    "        current = [imgs[i]]\n",
    "    else:\n",
    "        current.append(imgs[i])\n",
    "subgroups.append(current)\n",
    "\n",
    "print(f\"[info] formed {len(subgroups)} subgroups\")\n",
    "\n",
    "# --- stitch each subgroup separately ---\n",
    "subgroups = [g for g in subgroups if len(g) >= MIN_RUN_LEN]\n",
    "if \"DEBUG\" in globals() and DEBUG:\n",
    "    print(f\"[info] kept {len(subgroups)} subgroups with >= {MIN_RUN_LEN} images\")\n",
    "\n",
    "# Release memory\n",
    "imgs = None; gc.collect()\n",
    "\n",
    "for gi, group in enumerate(subgroups):\n",
    "    if len(group) < 2:\n",
    "        print(f\"[skip] subgroup {gi} has only 1 image\")\n",
    "        continue\n",
    "\n",
    "    print(f\"[info] stitching subgroup {gi} with {len(group)} images\")\n",
    "\n",
    "    H_to_anchor, _ = accumulate_homographies(group)\n",
    "    T, canvas_size, polys = compute_canvas_bounds(group, H_to_anchor)\n",
    "    if \"DEBUG\" in globals() and DEBUG:\n",
    "        print(f\"[info] subgroup {gi} canvas size: {canvas_size}\")\n",
    "\n",
    "    mosaic = multiband_blend_warped(group, H_to_anchor, T, canvas_size, debug_show=False)\n",
    "\n",
    "    out_path = f\"mosaic_{gi}.png\"\n",
    "    cv.imwrite(out_path, mosaic)\n",
    "    print(f\"[done] wrote {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
